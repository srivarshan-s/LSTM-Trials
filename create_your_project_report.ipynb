{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create-your-project-report.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWtu_vO0B-ZF"
      },
      "source": [
        "# **LSTM - create your project report**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A_JYmK9CDC7"
      },
      "source": [
        "Srivarshan 19BAI1078"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0mOhm8PB-LX"
      },
      "source": [
        "# importing libraries\n",
        "import numpy\n",
        "import sys\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mOrTgFtDQjT",
        "outputId": "c9cd5b58-55c8-4d4c-d02e-a22da8eb6c4f"
      },
      "source": [
        "# download data\n",
        "! rm /content/11-0.txt\n",
        "! rm /content/wonderland.txt\n",
        "! wget https://www.gutenberg.org/files/11/11-0.txt\n",
        "! mv /content/11-0.txt /content/wonderland.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/11-0.txt': No such file or directory\n",
            "rm: cannot remove '/content/wonderland.txt': No such file or directory\n",
            "--2021-11-23 04:49:28--  https://www.gutenberg.org/files/11/11-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 174313 (170K) [text/plain]\n",
            "Saving to: ‘11-0.txt’\n",
            "\n",
            "11-0.txt            100%[===================>] 170.23K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-11-23 04:49:28 (1.65 MB/s) - ‘11-0.txt’ saved [174313/174313]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz9p1L6zBv8W"
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N8MWg7E9EAQ7",
        "outputId": "396da0ff-b275-46b1-9a86-9d4494be8905"
      },
      "source": [
        "# print example text\n",
        "raw_text[:100]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ufeffthe project gutenberg ebook of alice’s adventures in wonderland, by lewis carroll\\n\\nthis ebook is fo'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZlhv4XSECBJ"
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm7_6ke8ELWD",
        "outputId": "eae2c563-7001-43db-bfd4-aac020664199"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  164047\n",
            "Total Vocab:  64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-g1zhg4EQXu",
        "outputId": "3198b864-2c60-49a7-de6b-5dea20165127"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  163947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31nsMIUdElqq"
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnoxa3YCEum8"
      },
      "source": [
        "# normalize\n",
        "X = X / float(n_vocab)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N82pVlyyEwou"
      },
      "source": [
        "# one hot encode the output variable\n",
        "y = to_categorical(dataY)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi11EOBvEzDI"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm-BB7TbE1Wd"
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wfZbcX_E4ZP",
        "outputId": "98782e5f-8bb5-4cc0-eb88-2f52b9e03024"
      },
      "source": [
        "# fit the data\n",
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 3.0151\n",
            "Epoch 00001: loss improved from inf to 3.01506, saving model to weights-improvement-01-3.0151.hdf5\n",
            "1281/1281 [==============================] - 51s 36ms/step - loss: 3.0151\n",
            "Epoch 2/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.8396\n",
            "Epoch 00002: loss improved from 3.01506 to 2.83959, saving model to weights-improvement-02-2.8396.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.8396\n",
            "Epoch 3/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.7651\n",
            "Epoch 00003: loss improved from 2.83959 to 2.76510, saving model to weights-improvement-03-2.7651.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.7651\n",
            "Epoch 4/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.6990\n",
            "Epoch 00004: loss improved from 2.76510 to 2.69899, saving model to weights-improvement-04-2.6990.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.6990\n",
            "Epoch 5/20\n",
            "1280/1281 [============================>.] - ETA: 0s - loss: 2.6399\n",
            "Epoch 00005: loss improved from 2.69899 to 2.63994, saving model to weights-improvement-05-2.6399.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.6399\n",
            "Epoch 6/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.5809\n",
            "Epoch 00006: loss improved from 2.63994 to 2.58088, saving model to weights-improvement-06-2.5809.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.5809\n",
            "Epoch 7/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.5292\n",
            "Epoch 00007: loss improved from 2.58088 to 2.52920, saving model to weights-improvement-07-2.5292.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.5292\n",
            "Epoch 8/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.4824\n",
            "Epoch 00008: loss improved from 2.52920 to 2.48239, saving model to weights-improvement-08-2.4824.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.4824\n",
            "Epoch 9/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.4392\n",
            "Epoch 00009: loss improved from 2.48239 to 2.43922, saving model to weights-improvement-09-2.4392.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.4392\n",
            "Epoch 10/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.3993\n",
            "Epoch 00010: loss improved from 2.43922 to 2.39925, saving model to weights-improvement-10-2.3993.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.3993\n",
            "Epoch 11/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.3620\n",
            "Epoch 00011: loss improved from 2.39925 to 2.36201, saving model to weights-improvement-11-2.3620.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.3620\n",
            "Epoch 12/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.3271\n",
            "Epoch 00012: loss improved from 2.36201 to 2.32711, saving model to weights-improvement-12-2.3271.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.3271\n",
            "Epoch 13/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.2946\n",
            "Epoch 00013: loss improved from 2.32711 to 2.29464, saving model to weights-improvement-13-2.2946.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.2946\n",
            "Epoch 14/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.2632\n",
            "Epoch 00014: loss improved from 2.29464 to 2.26316, saving model to weights-improvement-14-2.2632.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.2632\n",
            "Epoch 15/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.2307\n",
            "Epoch 00015: loss improved from 2.26316 to 2.23065, saving model to weights-improvement-15-2.2307.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.2307\n",
            "Epoch 16/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.2026\n",
            "Epoch 00016: loss improved from 2.23065 to 2.20264, saving model to weights-improvement-16-2.2026.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.2026\n",
            "Epoch 17/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.1749\n",
            "Epoch 00017: loss improved from 2.20264 to 2.17487, saving model to weights-improvement-17-2.1749.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.1749\n",
            "Epoch 18/20\n",
            "1280/1281 [============================>.] - ETA: 0s - loss: 2.1498\n",
            "Epoch 00018: loss improved from 2.17487 to 2.14976, saving model to weights-improvement-18-2.1498.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.1498\n",
            "Epoch 19/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.1243\n",
            "Epoch 00019: loss improved from 2.14976 to 2.12433, saving model to weights-improvement-19-2.1243.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.1243\n",
            "Epoch 20/20\n",
            "1281/1281 [==============================] - ETA: 0s - loss: 2.1003\n",
            "Epoch 00020: loss improved from 2.12433 to 2.10032, saving model to weights-improvement-20-2.1003.hdf5\n",
            "1281/1281 [==============================] - 46s 36ms/step - loss: 2.1003\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f707013b550>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrIcIH3rE7-N"
      },
      "source": [
        "# load the network weights\n",
        "filename = \"/content/weights-improvement-19-2.1243.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmRtSEisFJYA"
      },
      "source": [
        "# create reverse mapping of int to char\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cC6wt1rFSYV",
        "outputId": "734c28c0-c8d8-496d-e8fa-0c208760b807"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" eeping up\n",
            "the conversation a little.\n",
            "\n",
            "“’tis so,” said the duchess: “and the moral of that is—‘oh, ’t \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SMzuuUaFVU7",
        "outputId": "ac993bea-90b1-4526-afd2-e9aefe868253"
      },
      "source": [
        "# create the report\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "u know.”\n",
            "\n",
            "“i whnl y she mabc thet har head anoid and nooked an a lona of the word, \n",
            "“ho you dnn’t tooe to the soen i sean ” she mabc thit hnr heneled to the thre, “ho wou don’t keve to the then ”huh the whrt oi then ”huh the toote i shonld then to be io ano oo tie tooe ”huh the toot,”\n",
            "\n",
            "“i whnh you would bo i seen ” she hact said, “or tes toe tame then  the had netel hoe the tooe oi the sooee an the sooee  a dat rath the mook ou tro th the wood, \n",
            "“he aourse ”huh the was i saal?” said the manch hare.\n",
            "\n",
            "“ie aourse ”huh h shen to tee so toe thit ”ou,” said alice, \n",
            "“io you dnn’t know the wourd ”ou tooe ”ou to wei so tee then ”huh the was i saad?” said the corpouse the had not to the tooe, \n",
            "“h was a lint ii t aaied in a foor ”ith toe toile ” she said to herself, “ih aourse the kant of the tore of the sooee an the sooee  a dat rath the mook of the tar of the warte, and the waited to tee toae th the coere  and was no the wood  she had nete the tooe  she had netel here to the thnt hi a dond tan \n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS9bDwPGL0mj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}